# vital_guard_server.py
# VitalGuard AI å¥åº·ç›‘æµ‹ç³»ç»Ÿ - GCPæœåŠ¡å™¨ç«¯
# åŠŸèƒ½ï¼šæ¥æ”¶ESP32å¤šä¼ æ„Ÿå™¨æ•°æ®ã€å®æ—¶å¤„ç†ã€LLMå¥åº·åˆ†æ

import os
import json
import time
import threading
from datetime import datetime
from collections import deque
from typing import Optional, Deque, Dict, Any, List
from abc import ABC, abstractmethod

import numpy as np
from flask import Flask, request, jsonify
from openai import OpenAI, OpenAIError

# ======================= CONFIGURATION =======================
# --- LLM Configuration ---
API_KEY = os.environ.get("OPENAI_API_KEY", "your-api-key-here")
BASE_URL = None
MODEL_NAME = "gpt-4o-mini"
TEMPERATURE = 0.2
TIMEOUT_SEC = 45
RETRY = 2

# --- Data Processing Configuration ---
WINDOW_POINTS = 300  # çª—å£å¤§å°ï¼š300ä¸ªæ•°æ®ç‚¹ç”¨äºå¿ƒç‡è®¡ç®— (çº¦6ç§’@20msé‡‡æ ·)
PREDICTION_INTERVAL_SEC = 30  # LLMåˆ†æé—´éš”ï¼šæ¯30ç§’ç”Ÿæˆä¸€æ¬¡å¥åº·æŠ¥å‘Š
MAX_DATA_BUFFER_SIZE = 1500  # æœ€å¤§ç¼“å†²ï¼š1500ä¸ªæ•°æ®ç‚¹ (çº¦30ç§’æ•°æ®)

# --- Flask Server Configuration ---
FLASK_HOST = '0.0.0.0'
FLASK_PORT = 9999
DATA_FILE = 'vital_signs_data.jsonl'  # æŒä¹…åŒ–å­˜å‚¨æ–‡ä»¶

# --- Device Information ---
DEVICE_TYPE = "ESP32 VitalGuard"
SENSOR_LOCATION = "Wrist"


# ======================= DATA MODELS =======================
class VitalSignsDataPoint:
    """
    å•ä¸ªå‘¨æœŸçš„ç”Ÿå‘½ä½“å¾æ•°æ®ç‚¹æ¨¡å‹
    Represents a single cycle of vital signs measurement
    """

    def __init__(self,
                 cycle: int,
                 timestamp: str,
                 ir: int,
                 red: int,
                 temperature: float,
                 humidity: float,
                 force: float):
        self.cycle = cycle
        self.timestamp = timestamp
        # PPGæ•°æ®
        self.ir = ir
        self.red = red
        # ç¯å¢ƒæ•°æ®
        self.temperature = temperature
        self.humidity = humidity
        # åŠ›å­¦æ•°æ®
        self.force = force
        # æœåŠ¡å™¨æ¥æ”¶æ—¶é—´
        self.server_timestamp = datetime.now().isoformat()

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'cycle': self.cycle,
            'timestamp': self.timestamp,
            'ppg': {
                'ir': self.ir,
                'red': self.red
            },
            'temperature': self.temperature,
            'humidity': self.humidity,
            'force': self.force,
            'server_timestamp': self.server_timestamp
        }


# ======================= SHARED DATA STORE (ENHANCED) =======================
class SharedDataStore:
    """
    çº¿ç¨‹å®‰å…¨çš„å¤šä¼ æ„Ÿå™¨æ•°æ®å­˜å‚¨
    æ”¯æŒæ‰¹é‡å†™å…¥ã€æ—¶åºæŸ¥è¯¢ã€æ•°æ®èšåˆ
    """

    def __init__(self, max_size: int, persist_file: Optional[str] = None):
        self.max_size = max_size
        self.persist_file = persist_file

        # ä½¿ç”¨dequeå®ç°é«˜æ•ˆçš„FIFOç¼“å†²
        self.data_buffer: Deque[VitalSignsDataPoint] = deque(maxlen=max_size)
        self.lock = threading.Lock()

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_received = 0
        self.total_batches = 0

        print(f"âœ… SharedDataStore initialized: max_size={max_size}")

        # åˆ›å»ºæŒä¹…åŒ–æ–‡ä»¶
        if self.persist_file and not os.path.exists(self.persist_file):
            open(self.persist_file, 'w').close()
            print(f"ğŸ“ Created persistence file: {self.persist_file}")

    def add_batch(self, data_points: List[VitalSignsDataPoint]) -> int:
        """
        æ‰¹é‡æ·»åŠ æ•°æ®ç‚¹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        Returns: æˆåŠŸæ·»åŠ çš„æ•°æ®ç‚¹æ•°é‡
        """
        added_count = 0

        with self.lock:
            for point in data_points:
                self.data_buffer.append(point)
                added_count += 1

            self.total_received += added_count
            self.total_batches += 1

        # å¼‚æ­¥æŒä¹…åŒ–ï¼ˆé¿å…é˜»å¡ï¼‰
        if self.persist_file and added_count > 0:
            threading.Thread(
                target=self._persist_batch,
                args=(data_points,),
                daemon=True
            ).start()

        return added_count

    def _persist_batch(self, data_points: List[VitalSignsDataPoint]) -> None:
        """åå°çº¿ç¨‹ï¼šæ‰¹é‡æŒä¹…åŒ–æ•°æ®"""
        try:
            with open(self.persist_file, 'a') as f:
                for point in data_points:
                    f.write(json.dumps(point.to_dict()) + '\n')
        except Exception as e:
            print(f"âš ï¸  Persistence failed: {e}")

    def get_recent_data(self, count: int) -> Optional[Dict[str, np.ndarray]]:
        """
        è·å–æœ€è¿‘çš„Nä¸ªæ•°æ®ç‚¹ï¼ŒæŒ‰ä¼ æ„Ÿå™¨ç±»å‹ç»„ç»‡

        Returns:
            {
                'ir': np.array([...]),
                'red': np.array([...]),
                'temperature': np.array([...]),
                'humidity': np.array([...]),
                'force': np.array([...]),
                'timestamps': [...]
            }
            å¦‚æœæ•°æ®ä¸è¶³åˆ™è¿”å›None
        """
        with self.lock:
            buffer_size = len(self.data_buffer)

            if buffer_size < count:
                print(f"âš ï¸  Insufficient data: requested {count}, available {buffer_size}")
                return None

            # è·å–æœ€è¿‘çš„countä¸ªæ•°æ®ç‚¹
            recent_items = list(self.data_buffer)[-count:]

            # æŒ‰ä¼ æ„Ÿå™¨ç±»å‹ç»„ç»‡æ•°æ®
            return {
                'ir': np.array([item.ir for item in recent_items]),
                'red': np.array([item.red for item in recent_items]),
                'temperature': np.array([item.temperature for item in recent_items]),
                'humidity': np.array([item.humidity for item in recent_items]),
                'force': np.array([item.force for item in recent_items]),
                'timestamps': [item.timestamp for item in recent_items]
            }

    def get_ppg_window(self, window_size: int = 300) -> Optional[Dict[str, np.ndarray]]:
        """
        è·å–ç”¨äºå¿ƒç‡è®¡ç®—çš„PPGæ•°æ®çª—å£
        ä¸“é—¨ç”¨äºä¿¡å·å¤„ç†ç®—æ³•
        """
        data = self.get_recent_data(window_size)
        if data is None:
            return None

        return {
            'ir': data['ir'],
            'red': data['red'],
            'timestamps': data['timestamps']
        }

    def get_buffer_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å†²åŒºçŠ¶æ€ä¿¡æ¯"""
        with self.lock:
            current_size = len(self.data_buffer)
            return {
                'current_size': current_size,
                'max_size': self.max_size,
                'utilization': f"{current_size / self.max_size * 100:.1f}%",
                'total_received': self.total_received,
                'total_batches': self.total_batches
            }


# ======================= DATA VALIDATION =======================
class DataValidator:
    """æ•°æ®åŒ…éªŒè¯å™¨ï¼šç¡®ä¿æ¥æ”¶çš„æ•°æ®æ ¼å¼æ­£ç¡®"""

    @staticmethod
    def validate_batch_request(data: Dict[str, Any]) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯æ‰¹é‡æ•°æ®è¯·æ±‚æ ¼å¼
        Returns: (is_valid, error_message)
        """
        # å¿…éœ€å­—æ®µæ£€æŸ¥
        required_fields = ['device_id', 'batch_info', 'data']
        for field in required_fields:
            if field not in data:
                return False, f"Missing required field: {field}"

        # batch_infoéªŒè¯
        batch_info = data['batch_info']
        required_batch_fields = ['start_cycle', 'end_cycle', 'total_points']
        for field in required_batch_fields:
            if field not in batch_info:
                return False, f"Missing batch_info field: {field}"

        # æ•°æ®æ•°ç»„éªŒè¯
        data_array = data['data']
        if not isinstance(data_array, list) or len(data_array) == 0:
            return False, "Data array is empty or not a list"

        # éªŒè¯ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹çš„ç»“æ„ï¼ˆé‡‡æ ·éªŒè¯ï¼‰
        first_point = data_array[0]
        required_data_fields = ['cycle', 'timestamp', 'vital_signs']
        for field in required_data_fields:
            if field not in first_point:
                return False, f"Data point missing field: {field}"

        vital_signs = first_point['vital_signs']
        if 'ppg' not in vital_signs:
            return False, "Missing PPG data in vital_signs"

        ppg = vital_signs['ppg']
        if 'ir' not in ppg or 'red' not in ppg:
            return False, "PPG data must contain 'ir' and 'red'"

        return True, None


# ======================= LLM INTERFACE (UNCHANGED) =======================
class LLMInterface(ABC):
    """LLMå®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def predict(self, prompt: str) -> str:
        pass


class OpenAI_LLM(LLMInterface):
    """
    Concrete implementation of LLMInterface for OpenAI models.
    Handles API calls with retry logic.
    """

    def __init__(self, api_key: str, model: str, base_url: Optional[str] = None,
                 temperature: float = 0.2, timeout: int = 45, retries: int = 2):

        if api_key.strip() == 'sk-proj-...':
            print("API_KEY is not set. Please replace with your actual key.")

        self.model = model
        self.temperature = temperature
        self.timeout = timeout
        self.retries = retries
        self.client = OpenAI(api_key=api_key, base_url=base_url)

        print(f"INFO: OpenAI_LLM initialized with model: {self.model}")

    def predict(self, prompt: str) -> str:
        last_error = None
        for attempt in range(self.retries + 1):
            try:
                print(f"INFO: Sending request to OpenAI API (attempt {attempt + 1}/{self.retries + 1})...")

                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "You are a health monitoring AI assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.temperature,
                    timeout=self.timeout
                )
                print("âœ… LLM response received")
                return response.choices[0].message.content.strip()

            except OpenAIError as e:
                last_error = e
                print(f"âš ï¸  LLM API call failed: {e}")
                if attempt < self.retries:
                    time.sleep(1.0)

        raise RuntimeError(f"LLM failed after {self.retries + 1} attempts: {last_error}")


# ======================= FLASK SERVER =======================
def create_flask_app(data_store: SharedDataStore) -> Flask:
    """
    Creates and configures the Flask application.
    Args:
        data_store: The shared data store instance to write incoming data to.
    Returns:
        Configured Flask app instance.
    """
    app = Flask(__name__)

    @app.route('/')
    def home():
        """Server status endpoint."""
        buffer_info = data_store.get_buffer_info()
        return jsonify({
            "status": "running",
            "service": "VitalGuard AI Health Monitoring System",
            "version": "2.0",
            "buffer_status": buffer_info,
            "endpoints": {
                "/": "Server status",
                "/api/vitals": "Receive vital signs data (POST)",
                "/api/buffer": "Check buffer status (GET)",
                "/api/recent": "Get recent data (GET)",
                "/health": "Health check for server (GET)"
            }
        })

    @app.route('/api/vitals', methods=['POST'])
    def receive_vital_signs():
        """
        æ¥æ”¶æ¥è‡ªESP32çš„ç”Ÿå‘½ä½“å¾æ•°æ®
        æ”¯æŒæ‰¹é‡æ•°æ®ä¼ è¾“ï¼ˆæ¨èï¼‰å’Œå•ç‚¹ä¼ è¾“ï¼ˆå…¼å®¹ï¼‰
        """
        try:
            request_data = request.get_json()

            if not request_data:
                return jsonify({
                    "success": False,
                    "error": {
                        "code": "EMPTY_REQUEST",
                        "message": "Request body is empty"
                    }
                }), 400

            # ===== æ‰¹é‡æ•°æ®å¤„ç† (Recommended) =====
            if 'data' in request_data and 'batch_info' in request_data:
                # éªŒè¯æ•°æ®æ ¼å¼
                is_valid, error_msg = DataValidator.validate_batch_request(request_data)
                if not is_valid:
                    return jsonify({
                        "success": False,
                        "error": {
                            "code": "VALIDATION_FAILED",
                            "message": error_msg
                        }
                    }), 400

                # è§£ææ‰¹é‡æ•°æ®
                device_id = request_data['device_id']
                batch_info = request_data['batch_info']
                data_points_raw = request_data['data']

                # è½¬æ¢ä¸ºVitalSignsDataPointå¯¹è±¡
                data_points = []
                parsing_errors = []

                for idx, point in enumerate(data_points_raw):
                    try:
                        vital_signs = point['vital_signs']
                        ppg = vital_signs['ppg']

                        data_point = VitalSignsDataPoint(
                            cycle=point['cycle'],
                            timestamp=point['timestamp'],
                            ir=ppg['ir'],
                            red=ppg['red'],
                            temperature=vital_signs.get('temperature', 0.0),
                            humidity=vital_signs.get('humidity', 0.0),
                            force=vital_signs.get('force', 0.0)
                        )
                        data_points.append(data_point)
                    except Exception as e:
                        parsing_errors.append(f"Point {idx}: {str(e)}")

                # æ‰¹é‡æ·»åŠ åˆ°æ•°æ®å­˜å‚¨
                added_count = data_store.add_batch(data_points)

                # è¿”å›å¤„ç†ç»“æœ
                response = {
                    "success": True,
                    "message": f"Batch processed successfully",
                    "device_id": device_id,
                    "batch_info": {
                        "cycles": f"{batch_info['start_cycle']}-{batch_info['end_cycle']}",
                        "total_received": len(data_points_raw),
                        "successfully_stored": added_count,
                        "parsing_errors": len(parsing_errors)
                    }
                }

                if parsing_errors:
                    response["warnings"] = parsing_errors[:10]  # åªè¿”å›å‰10ä¸ªé”™è¯¯

                print(f"ğŸ“¦ Batch received: {added_count} points from {device_id}")
                return jsonify(response), 201

            # ===== å•ç‚¹æ•°æ®å¤„ç† (Backward Compatibility) =====
            else:
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required = ['cycle', 'timestamp', 'ppg', 'temperature']
                if not all(k in request_data for k in required):
                    return jsonify({
                        "success": False,
                        "error": {
                            "code": "MISSING_FIELDS",
                            "message": f"Required fields: {required}"
                        }
                    }), 400

                ppg = request_data['ppg']
                data_point = VitalSignsDataPoint(
                    cycle=request_data['cycle'],
                    timestamp=request_data['timestamp'],
                    ir=ppg['ir'],
                    red=ppg['red'],
                    temperature=request_data['temperature'],
                    humidity=request_data.get('humidity', 0.0),
                    force=request_data.get('force', 0.0)
                )

                data_store.add_batch([data_point])

                return jsonify({
                    "success": True,
                    "message": "Single data point received"
                }), 201

        except Exception as e:
            print(f"âŒ Error processing request: {e}")
            import traceback
            traceback.print_exc()

            return jsonify({
                "success": False,
                "error": {
                    "code": "SERVER_ERROR",
                    "message": str(e)
                }
            }), 500

    @app.route('/api/buffer', methods=['GET'])
    def get_buffer_status():
        """è·å–æ•°æ®ç¼“å†²åŒºçŠ¶æ€"""
        try:
            buffer_info = data_store.get_buffer_info()
            return jsonify({
                "success": True,
                "buffer": buffer_info
            }), 200
        except Exception as e:
            return jsonify({
                "success": False,
                "error": str(e)
            }), 500

    @app.route('/api/recent', methods=['GET'])
    def get_recent_data():
        """è·å–æœ€è¿‘çš„æ•°æ®ç‚¹ï¼ˆç”¨äºè°ƒè¯•å’Œå¯è§†åŒ–ï¼‰"""
        try:
            limit = request.args.get('limit', default=50, type=int)
            limit = min(limit, 500)  # æœ€å¤šè¿”å›500ä¸ªç‚¹

            recent_data = data_store.get_recent_data(limit)

            if recent_data is None:
                return jsonify({
                    "success": False,
                    "message": "Insufficient data",
                    "available": data_store.get_buffer_info()['current_size']
                }), 404

            # æ ¼å¼åŒ–è¿”å›æ•°æ®
            response_data = {
                "success": True,
                "count": limit,
                "data": {
                    "ppg": {
                        "ir": recent_data['ir'].tolist(),
                        "red": recent_data['red'].tolist()
                    },
                    "temperature": recent_data['temperature'].tolist(),
                    "humidity": recent_data['humidity'].tolist(),
                    "force": recent_data['force'].tolist(),
                    "timestamps": recent_data['timestamps']
                }
            }

            return jsonify(response_data), 200

        except Exception as e:
            return jsonify({
                "success": False,
                "error": str(e)
            }), 500

    @app.route('/health', methods=['GET'])
    def health_check():
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ˆç”¨äºè´Ÿè½½å‡è¡¡å™¨ï¼‰"""
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "service": "VitalGuard AI"
        }), 200

    return app


# ======================= MAIN APPLICATION =======================
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("=" * 70)
    print("  ğŸ©º VitalGuard AI - Health Monitoring System")
    print("  ğŸ“¡ Real-time Vital Signs Processing Server")
    print("=" * 70)
    print()

    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    print("ğŸ”§ Initializing data store...")
    data_store = SharedDataStore(
        max_size=MAX_DATA_BUFFER_SIZE,
        persist_file=DATA_FILE
    )

    # åˆ›å»ºFlaskåº”ç”¨
    print("ğŸ”§ Creating Flask server...")
    app = create_flask_app(data_store)

    # å¯åŠ¨æœåŠ¡å™¨
    print(f"ğŸš€ Starting server on {FLASK_HOST}:{FLASK_PORT}...")
    print(f"ğŸ“Š Buffer capacity: {MAX_DATA_BUFFER_SIZE} data points")
    print(f"ğŸ’¾ Data persistence: {DATA_FILE}")
    print()
    print("=" * 70)
    print("âœ… Server is ready to receive data from ESP32")
    print("ğŸ”— Send POST requests to: http://your-server-ip:9999/api/vitals")
    print("=" * 70)
    print("\nPress Ctrl+C to stop the server\n")

    try:
        app.run(host=FLASK_HOST, port=FLASK_PORT, debug=False, threaded=True)
    except KeyboardInterrupt:
        print("\nâš ï¸  Received shutdown signal")
    finally:
        print("ğŸ‘‹ Server stopped. Goodbye!")